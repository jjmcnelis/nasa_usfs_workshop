{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import warnings\n",
    "from math import ceil\n",
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from shapely.geometry import shape\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm, colors\n",
    "from IPython.display import display\n",
    "\n",
    "import ipyleaflet as mwg\n",
    "from ipyleaflet import Map, LayerGroup, GeoJSON, CircleMarker\n",
    "from ipywidgets import Layout, Button, IntProgress, Output, HBox, VBox, HTML, interactive\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# app settings\n",
    "\n",
    "#font = {\"family\": \"normal\", \"weight\": \"normal\", \"size\": 16}  # matplotlib ->\n",
    "#plt.rcParams['figure.figsize'] = [14, 5]\n",
    "#plt.rc(\"font\", **font) # <- some matplotlib settings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "auth = dict(ORNL_DAAC_USER_NUM=str(32863))\n",
    "\n",
    "smvdownload = \"https://daac.ornl.gov/cgi-bin/viz/download.pl?\"\n",
    "smvdatasets = pd.read_csv(\n",
    "    \"docs/smvdatasets.csv\", \n",
    "    index_col=\"dataset\", \n",
    "    header=0)\n",
    "\n",
    "ignore_variables = [\n",
    "    \"sample\",\"time\",\"stat\",\"lat\",\"lon\",\"FLUXNET_surface\",\"FLUXNET_rootzone\"]\n",
    "\n",
    "# usfs shapefile fields; only applies to Yaxing's workshop -->>\n",
    "fields = [\n",
    "    \"FORESTNUMB\",\"DISTRICTNU\",\"REGION\",\"GIS_ACRES\",\"MIN\",\"MEDIAN\",\"MAX\",\n",
    "    \"RANGE\",\"SUM\",\"VARIETY\",\"MINORITY\",\"MAJORITY\",\"COUNT\"]\n",
    "\n",
    "site_details = \"\"\"\n",
    "REGION:   {REGION}\n",
    "ACRES:    {GIS_ACRES}\n",
    "MIN:      {MIN}\n",
    "MEDIAN:   {MEDIAN}\n",
    "MAX:      {MAX}\n",
    "RANGE:    {RANGE}\n",
    "SUM:      {SUM}\n",
    "VARIETY:  {VARIETY}\n",
    "MINORITY: {MINORITY}\n",
    "MAJORITY: {MAJORITY}\n",
    "COUNT:    {COUNT}\n",
    "\"\"\"\n",
    "#{FORESTNAME} ({FORESTNUMB})\n",
    "#{DISTRICTNA} ({DISTRICTNU})\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# widget settings\n",
    "\n",
    "bmap = mwg.basemap_to_tiles(mwg.basemaps.Esri.WorldImagery)    # map widget \n",
    "map_args = dict(\n",
    "    center=(32.75, -109), \n",
    "    zoom=7, \n",
    "    scroll_wheel_zoom=True)\n",
    "\n",
    "submit_args = dict(                                            # submit button\n",
    "    description=\"Submit\", \n",
    "    disabled=True, \n",
    "    button_style=\"success\")\n",
    "\n",
    "progress_args = dict(                                          # progress bar\n",
    "    description=\"Progress: \", \n",
    "    layout=Layout(width=\"95%\"))\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# functions that don't support the all-in-one application\n",
    "\n",
    "\n",
    "def poly_mapper(lyr, mw=\"25%\", ow=\"75%\", zoom=8):\n",
    "    \"\"\"Generates the map/plot side-by-side widget container.\"\"\"\n",
    "\n",
    "    l = (lyr[\"layer\"].layer, lyr.points, bmap,)\n",
    "    m = Map(layers=l, center=(lyr[\"lat\"], lyr[\"lon\"]), zoom=zoom, width=mw)\n",
    "    o = Output(layout={\"width\": ow})\n",
    "    \n",
    "    return((m,o))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "# other helpers\n",
    "\n",
    "figure_args = dict(ncols=1, sharex=True, figsize=(10,5))\n",
    "bar_args = dict(stacked=True, colormap=\"tab20c\", legend=False)\n",
    "legend_ncols = lambda df: ceil(len(df.index)/10)   \n",
    "download_msg = \"\"\"<p style=\"text-align:center;\">\n",
    "Click <b>Submit</b> to download Soil Moisture Visualizer data for this site.\n",
    "<br></p>\"\"\"\n",
    "\n",
    "\n",
    "def get_ancillary_data(geojson):\n",
    "    \"\"\" \"\"\"\n",
    "    features, cols = from_geojson(geojson)            # get features and cols\n",
    "\n",
    "    layers = []                                       # a temporary list \n",
    "    for i, feat in enumerate(features):               # loop over features\n",
    "        lyrd = get_layer_data(i, feat, opac=0, samp=False)\n",
    "        lyrm = GeoJSON(\n",
    "            data=lyrd[0], \n",
    "            hover_style={\"color\": cols[i], \"fillOpacity\": 0.1})\n",
    "        layers.append((i, lyrd[2], lyrd[3], lyrm, lyrd[5]))\n",
    "    layers = pd.DataFrame(layers, columns=[\"id\",\"lat\",\"lon\",\"layer\",\"attrs\"])\n",
    "\n",
    "    return(layers)\n",
    "\n",
    "\n",
    "def get_nan_summary(xrdataset): \n",
    "    \"\"\" \"\"\"\n",
    "    nandict = {\"in situ\": {}, \"airborne\": {}, \"spaceborne\": {}}\n",
    "\n",
    "    for pt in nandict.keys():\n",
    "\n",
    "        # for percentage: ----------------------------------------------------\n",
    "        \"\"\"# get the datasets for the current platform\n",
    "        ds = xrds.filter_by_attrs(type=pt).sel(stat=\"Mean\", drop=True)\n",
    "\n",
    "        # get fraction of null dataset by timestep for all samples\n",
    "        dsnull = ds.isnull()\n",
    "\n",
    "        # get variables with nodata; variables with data; valid counts\n",
    "        nodata, yesdata, data = [], [], {}\n",
    "        for name, dataset in dsnull.items():\n",
    "            if dataset.data.all(): #dataset.isnull().mean()==1\n",
    "                nodata.append(name)\n",
    "            else:\n",
    "                yesdata.append(name)\n",
    "                dataset.data = np.logical_not(dataset.data)\n",
    "                data[name] = dataset.mean(\"sample\").data\"\"\"\n",
    "        # --------------------------------------------------------------------\n",
    "\n",
    "        # get the datasets for the current platform\n",
    "        pds = xrdataset.filter_by_attrs(type=pt).sel(stat=\"Mean\", drop=True)\n",
    "        timelen, samplelen = pds.time.size, pds.sample.size\n",
    "        potential_obs_count = timelen*samplelen\n",
    "\n",
    "        # get variables with nodata; variables with data; valid counts\n",
    "        nodata, yesdata, obscount = [], [], {}\n",
    "        for name, dataset in pds.items():\n",
    "            if allnan(dataset):\n",
    "                nodata.append(name)\n",
    "            else:\n",
    "                yesdata.append(name)\n",
    "                obscount[name], obstotal = [], 0\n",
    "                for i in range(samplelen):\n",
    "                    samp = dataset.sel(sample=i)\n",
    "                    count = numvalid(samp)\n",
    "                    obscount[name].append(count) #/potential_obs_count*100\n",
    "                    obstotal += count\n",
    "                obscount[name].append(potential_obs_count-obstotal)\n",
    "        \n",
    "        # update summary dictionary\n",
    "        ix = list(range(samplelen))+[\"nan\"]   \n",
    "        nandict[pt].update({                      \n",
    "            \"nodata\": nodata, \n",
    "            \"yesdata\": yesdata, \n",
    "            \"summary\": pd.DataFrame(obscount, index=ix)})\n",
    "\n",
    "    return(nandict)\n",
    "\n",
    "\n",
    "def get_nan_plot(nandict):\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    stypes = []\n",
    "    for stype, nandata in nandict.items():\n",
    "        cnt = len(nandata[\"yesdata\"])\n",
    "        if cnt!=0:\n",
    "            stypes.append((stype, nandata[\"summary\"], cnt))\n",
    "\n",
    "    if len(stypes)==1:\n",
    "        df = stypes[0][1]\n",
    "        df.T.plot.barh(stacked=True, colormap=\"tab20c\", figsize=(10,5))\n",
    "        plt.legend(ncol=legend_ncols(df), title=\"sample\")\n",
    "    else:\n",
    "        st = sorted(stypes, key=lambda x: x[2], reverse=True)\n",
    "        fig, axs = plt.subplots(\n",
    "            nrows=len(st), \n",
    "            gridspec_kw={'height_ratios': [i[2] for i in st]}, \n",
    "            **figure_args)\n",
    "        for i, d in enumerate(st):\n",
    "            d[1].T.plot.barh(ax=axs[i],**bar_args)\n",
    "        fig.tight_layout()\n",
    "        axs[0].legend(ncol=legend_ncols(st[0][1]), title=\"sample\")\n",
    "        axs[0].set_title(\"n observations by dataset\")\n",
    "        for i, ax in enumerate(axs):\n",
    "            xlim = ax.get_xlim()\n",
    "            ax.set_xlim(xlim[0], xlim[1]/2)\n",
    "            label = ax.set_xlabel(str(ceil(xlim[1]))+\" total\")\n",
    "            ax.xaxis.set_label_coords(1.05, -0.05)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "# SMV sample dataset formatters\n",
    "\n",
    "numvalid = lambda v: np.count_nonzero(~np.isnan(v.data))\n",
    "allnan = lambda v: numvalid(v)==0\n",
    "\n",
    "latatts = dict(\n",
    "    standard_name=\"latitude\",\n",
    "    long_name=\"sample latitude\",\n",
    "    units=\"degrees_north\")\n",
    "\n",
    "lonatts = dict(\n",
    "    standard_name=\"latitude\",\n",
    "    long_name=\"sample latitude\",\n",
    "    units=\"degrees_north\")\n",
    "\n",
    "pt_style = dict(\n",
    "    radius=6, \n",
    "    stroke=False,\n",
    "    fill_opacity=0.6, \n",
    "    fill_color=\"black\")\n",
    "\n",
    "\n",
    "def txt_to_pd(response_text):\n",
    "    \"\"\"Parses response.text to data frame with date index.\"\"\"\n",
    "    \n",
    "    f = StringIO(response_text)                      # get file from string\n",
    "\n",
    "    df = pd.read_csv(f, header=4, index_col=\"time\")  # read to df\n",
    "    df.index = pd.to_datetime(df.index)              # convert index to dates\n",
    "    \n",
    "    return(df)\n",
    "\n",
    "\n",
    "def split_pd(col):\n",
    "    \"\"\"Splits pd column by ; and set all values to float, nan.\"\"\"\n",
    "    \n",
    "    df = col.str.split(\";\",n=2,expand=True)           # split col by ;\n",
    "    df = df.replace('', np.nan)                       # set '' to nan\n",
    "    df = df.astype(float)                             # set all to float\n",
    "    df.columns = [\"Max\",\"Mean\",\"Min\"]                 # add column names\n",
    "    \n",
    "    return(df)\n",
    "\n",
    "\n",
    "def pd_to_xr(dataset, df):\n",
    "    \"\"\"Makes an xr.Dataset from a pandas column (series) and coords.\"\"\"\n",
    "\n",
    "    a = smvdatasets.loc[dataset].to_dict()\n",
    "    x = xr.DataArray(df, name=dataset, attrs=a)\n",
    "    x = x.rename(dict(dim_1=\"stat\"))\n",
    "    \n",
    "    return(x)\n",
    "\n",
    "\n",
    "def get_sample_xr(samp):\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    d = [\"sample\"]                          \n",
    "    s = xr.DataArray(data=[samp.id], dims=d) # get sample, lat, lon xr arrays\n",
    "    y = xr.DataArray(data=[samp.lat], coords=[s], dims=d, attrs=latatts)\n",
    "    x = xr.DataArray(data=[samp.lon], coords=[s], dims=d, attrs=lonatts)\n",
    "\n",
    "    df = samp.df                                         # get the sample df\n",
    "    ds = {}\n",
    "    for dataset in df.columns:\n",
    "        if (\"FLUXNET\" not in dataset) & (\"PBOH2O\" not in dataset): # disabled\n",
    "            split_column = split_pd(df[dataset])\n",
    "            ds[dataset] = pd_to_xr(dataset, split_column)\n",
    "\n",
    "    xds = xr.merge(ds.values())                          # merge to one xr\n",
    "    xds = xds.assign_coords(lat=y, lon=x)                # add coord arrays\n",
    "    \n",
    "    return(xds)\n",
    "\n",
    "\n",
    "def get_null_summary(xrdataset):\n",
    "    \"\"\" \"\"\"\n",
    "    percent = {}\n",
    "    typebool = {\"in situ\": False, \n",
    "                \"airborne\": False, \n",
    "                \"spaceborne\": False}                             # summarize\n",
    "    for name, dataset in xrdataset.items():\n",
    "        t = dataset.attrs[\"type\"]\n",
    "        dsnull = dataset.isnull().sel(stat=\"Mean\", drop=True)    # get null dataset\n",
    "        if (not dsnull.data.all()) & (name not in ignore_variables):\n",
    "            typebool[t] = True\n",
    "            percent[name] = np.logical_not(dsnull.data).mean() \n",
    "    \n",
    "    return((typebool, percent))\n",
    "\n",
    "\n",
    "def get_symbology(typebool):\n",
    "    \"\"\" \"\"\"\n",
    "    return({\n",
    "        \"fill_color\": \"#fdc086\" if typebool[\"in situ\"] else \"gray\",\n",
    "        \"color\": \"#beaed4\" if typebool[\"airborne\"] else None,\n",
    "        \"stroke\": True if typebool[\"airborne\"] else None})\n",
    "\n",
    "\n",
    "class Sample(object):\n",
    "\n",
    "\n",
    "    def __init__(self, i, lat, lon):\n",
    "        \"\"\"Inits with id,lat,lon; makes request string, map point.\"\"\"\n",
    "        self.id = i\n",
    "        self.lat = lat \n",
    "        self.lon = lon\n",
    "\n",
    "        self.on = False\n",
    "        self.pt = CircleMarker(location=(lat, lon), **pt_style)  \n",
    "        self.dl = smvdownload+\"lt={0}&ln={1}&d=smap\".format(lat, lon)\n",
    "\n",
    "    def update(self, **kwargs):\n",
    "        for arg, val in kwargs.items():\n",
    "            setattr(self.pt, arg, val)\n",
    "\n",
    "\n",
    "    def toggle(self, event, type, coordinates):\n",
    "        opac = 0.1 if self.on else 0.6                    # determine opacity\n",
    "        self.update(opacity=opac)                         # set opacity\n",
    "        self.on = False if self.on else True              # toggle status\n",
    "\n",
    "\n",
    "    def submit(self):\n",
    "        \"\"\"Called by parent. Downloads url. Updates status.\"\"\"\n",
    "        \n",
    "        self.response = requests.get(self.dl, cookies=auth)# download\n",
    "        self.df = txt_to_pd(self.response.text)            # read to df\n",
    "        self.xr = get_sample_xr(self)                      # get xr dataset\n",
    "        self.pt.on_click(self.toggle)                      # callback switch style\n",
    "        self.summary = get_null_summary(self.xr)           # get null summary\n",
    "        self.symbology = get_symbology(self.summary[0])\n",
    "        self.on = True                                     # toggle status on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Sample(1, lat=30, lon=-90)\n",
    "test.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fillColor': 'gray', 'color': None, 'stroke': None}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(test)\n",
    "test.symbology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "# input polygon data\n",
    "\n",
    "latf = \"docs/EASE2_M09km.lats.3856x1624x1.double\"\n",
    "lonf = \"docs/EASE2_M09km.lons.3856x1624x1.double\"\n",
    "\n",
    "lats = np.fromfile(latf, dtype=np.float64).flatten() \n",
    "lons = np.fromfile(lonf, dtype=np.float64).flatten()\n",
    "crds = np.dstack((lats,lons))[0]\n",
    "\n",
    "\n",
    "def get_colors(n, cmap=cm.Set3):\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    cspace = np.linspace(0.0, 1.0, n)           # 1\n",
    "    rgb = cmap(cspace)                          # 2\n",
    "    cols = [colors.to_hex(c[0:3]) for c in rgb] # 3\n",
    "\n",
    "    return(cols)\n",
    "\n",
    "def from_geojson(input_geojson):\n",
    "    \"\"\" \"\"\"\n",
    "    with open(input_geojson, \"r\") as f:\n",
    "        shapes = json.load(f)\n",
    "    features = shapes[\"features\"]\n",
    "    cols = get_colors(len(features))\n",
    "    return((features, cols))\n",
    "\n",
    "\n",
    "def get_ease(shapely_geom):\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    bnds = shapely_geom.bounds \n",
    "    ease = crds[\n",
    "        (bnds[1]<lats) & (lats<bnds[3]) &     # ybnds < lat < ybnds\n",
    "        (bnds[0]<lons) & (lons<bnds[2])]      # xbnds < lon < xbnds\n",
    "\n",
    "    ease_reduced = []\n",
    "    for p in ease:\n",
    "        shapely_pt = shape({                  # input to shapely.shape is a\n",
    "            \"type\": \"Point\",                  # python dict equivalent of\n",
    "            \"coordinates\": (p[1], p[0])})     # geojson point geometry\n",
    "        \n",
    "        if shapely_geom.contains(shapely_pt): # if point inside poly\n",
    "            ease_reduced.append([p[0], p[1]]) # return lat, lon tuple\n",
    "\n",
    "    return(ease_reduced)\n",
    "\n",
    "\n",
    "def get_properties(prop):\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    details, stats = {}, {\"MEAN\": [], \"STD\": []}\n",
    "    for key, value in prop.items():\n",
    "        if key in fields:\n",
    "            details[key] = value\n",
    "        elif \"MEAN_\" in key:\n",
    "            stats[\"MEAN\"].append(value)\n",
    "        elif \"STD_\" in key:\n",
    "            stats[\"STD\"].append(value)\n",
    "        else:\n",
    "            pass\n",
    "    yr = pd.date_range(\n",
    "        start=\"1985\",\n",
    "        freq=\"1Y\",\n",
    "        periods=len(stats[\"MEAN\"]))\n",
    "    stats = pd.DataFrame(stats, index=yr)\n",
    "\n",
    "    return((details, stats))\n",
    "\n",
    "\n",
    "def get_layer_data(i, feat, col=\"#FFFFFF\", opac=0.4, samp=True):\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    shapely_geom = shape(feat[\"geometry\"])              # shapely geom\n",
    "    ease = get_ease(shapely_geom) if samp else None     # ease grid points\n",
    "    cent = shapely_geom.centroid                        # centroid\n",
    "    lat, lon = cent.y, cent.x                           # lat, lon\n",
    "    details, stats = get_properties(feat[\"properties\"])\n",
    "    feat[\"properties\"].update({\n",
    "        \"id\": i, \n",
    "        \"style\": {\n",
    "            \"weight\": 0.75,\n",
    "            \"color\": col,\n",
    "            \"fillColor\": col,\n",
    "            \"fillOpacity\": opac}})\n",
    "\n",
    "    return((feat, ease, lat, lon, stats, details))\n",
    "\n",
    "\n",
    "class Layer(object):\n",
    "\n",
    "\n",
    "    def __init__(self, i, feat, col=None):\n",
    "        \"\"\"Inits with id,lat,lon; makes request string, map point.\"\"\"\n",
    "        \n",
    "        layer_data = get_layer_data(i, feat, col)\n",
    "        \n",
    "        self.id = i\n",
    "        self.feat = layer_data[0]\n",
    "        self.ease = layer_data[1]\n",
    "        self.lat = layer_data[2]\n",
    "        self.lon = layer_data[3]\n",
    "        self.stats = layer_data[4]\n",
    "        self.details = layer_data[5]\n",
    "\n",
    "        self.layer = GeoJSON(\n",
    "            data=self.feat,\n",
    "            hover_style={\n",
    "                \"color\": \"white\", \n",
    "                \"fillOpacity\": 0.8})\n",
    "        self.layer.on_click(self.toggle)\n",
    "\n",
    "        self.dl = False    # downloaded or nah?\n",
    "        self.on = False    # toggle on or nah?\n",
    "\n",
    "\n",
    "    def toggle(self, **kwargs):\n",
    "        \"\"\"Routine for when a new USFS polygon is selected.\"\"\"\n",
    "\n",
    "        if list(kwargs.keys()) != ['event', 'properties']: # check event\n",
    "            return(None)                                   # skip basemap\n",
    "        \n",
    "        self.on = False if self.on else True               # update status\n",
    "    \n",
    "\n",
    "    def update(self, **kwargs):\n",
    "        for arg, val in kwargs.items():\n",
    "            setattr(self.layer, arg, val)\n",
    "            \n",
    "    \n",
    "    def getui(self):\n",
    "        \"\"\" \"\"\"\n",
    "        self.groupbyui = radio_checkbox(plot_options)\n",
    "        return(self.groupbyui)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JupyterSMV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "# app\n",
    "\n",
    "pt_status_on = dict(\n",
    "    opacity=0.5,\n",
    "    stroke=True, \n",
    "    color=\"white\")\n",
    "\n",
    "pt_status_off = dict(\n",
    "    opacity=0.6,\n",
    "    stroke=False, \n",
    "    color=\"black\")\n",
    "\n",
    "sample_header = [\n",
    "    \"id\",\n",
    "    \"lat\",\n",
    "    \"lon\",\n",
    "    \"samp\"\n",
    "]\n",
    "\n",
    "layer_header = [\n",
    "    \"id\",\n",
    "    \"lat\",\n",
    "    \"lon\",\n",
    "    \"layer\",\n",
    "    \"samples\",\n",
    "    \"points\",\n",
    "    \"xr\"\n",
    "]\n",
    "\n",
    "\n",
    "def get_output_layout(w=\"95%\", b=\"1px solid lightgray\"):\n",
    "    \"\"\" \"\"\"\n",
    "    return({\"width\": w, \"border\": b})\n",
    "\n",
    "\n",
    "class JupyterSMV(object):\n",
    "    \"\"\"App.\"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self, primary=None, ancillary=None, freedom=False):\n",
    "\n",
    "        self.polys = LayerGroup()\n",
    "        self.points = LayerGroup()\n",
    "        self.apolys = LayerGroup()\n",
    "        self.mapw = Map(\n",
    "            layers=(bmap, self.apolys, self.polys, self.points,), **map_args)\n",
    "\n",
    "        self.submit = Button(**submit_args)\n",
    "        self.submit.on_click(self.submit_handler)\n",
    "        self.progress = IntProgress(**progress_args)\n",
    "        \n",
    "        if primary:                                   # if given, \n",
    "            self.load_features(primary)               # load input features\n",
    "        if ancillary:\n",
    "            self.load_ancillary(ancillary)\n",
    "\n",
    "        layout = [self.mapw, HBox([self.submit, self.progress])]\n",
    "        self.out1 = Output(layout=get_output_layout(w=\"80%\"))\n",
    "        self.out2 = Output(layout=get_output_layout(w=\"20%\"))\n",
    "        self.ui = VBox(layout + [HBox([self.out1, self.out2])])\n",
    "\n",
    "\n",
    "    def load_features(self, infeats):\n",
    "        \"\"\" \"\"\"\n",
    "        features, cols = from_geojson(infeats)        # get features and cols\n",
    "\n",
    "        layers = []                                   # a temporary list \n",
    "        for i, feat in enumerate(features):           # loop over features\n",
    "            \n",
    "            poly = Layer(i, feat, cols[i])            # get Layer class\n",
    "            poly.layer.on_click(self.layer_click_handler)  # global callback\n",
    "            self.polys.add_layer(poly.layer)          # add to poly grp\n",
    "\n",
    "            pts, samps = LayerGroup(), []             # points group; Samples\n",
    "            for j, p in enumerate(poly.ease):         # loop EASE grid pts\n",
    "                s = Sample(j, p[0], p[1])             # make Sample instance\n",
    "                pts.add_layer(s.pt)                   # add to points group\n",
    "                samps.append((j, p[0], p[1], s))      # append tuple to list  \n",
    "\n",
    "            samps = pd.DataFrame(samps, columns=sample_header)       # samples\n",
    "            layers.append((i,poly.lat,poly.lon,poly,samps,pts,None)) # append\n",
    "        \n",
    "        self.layers = pd.DataFrame(layers, columns=layer_header)     # layers\n",
    "        self.selected = None\n",
    "\n",
    "\n",
    "    def load_ancillary(self, infeats):\n",
    "        \"\"\" \"\"\"          \n",
    "        self.alayers = get_ancillary_data(infeats)\n",
    "        for layer in self.alayers.layer:\n",
    "            self.apolys.add_layer(layer)\n",
    "\n",
    "\n",
    "    def submit_handler(self, b):\n",
    "        \"\"\"Resets UI and sends requests to SMV when new submit.\"\"\"\n",
    "        \n",
    "        layer_row = self.layers.iloc[self.selected]\n",
    "        sample = layer_row.samples[\"samp\"].tolist()\n",
    "\n",
    "        self.progress.min = 0                      # reset progress bar\n",
    "        self.progress.max = len(sample)\n",
    "        self.progress.value = 0\n",
    "        \n",
    "        for s in sample:                           # loop over sample pts\n",
    "            self.progress.value += 1               # update progress bar\n",
    "            s.update(**s.symbology)                # update style\n",
    "            s.submit()                             # download the data\n",
    "        layer_row.layer.dl = True                  # set dl status to True\n",
    "        \n",
    "        xrds = xr.concat([s.xr for s in sample], \"sample\")\n",
    "        lnan = get_nan_summary(xrds)\n",
    "        self.layers.at[self.selected,\"xr\"] = xrds  # make xr dataset\n",
    "        self.layers.iloc[self.selected].layer.nan = lnan\n",
    "\n",
    "        self.out1.clear_output(); self.out2.clear_output()\n",
    "        with self.out1:                            # display a summary of nan\n",
    "            get_nan_plot(lnan)\n",
    "        with self.out2:\n",
    "            print(site_details.format(**layer_row.layer.details))\n",
    "\n",
    "\n",
    "    def layer_click_handler(self, **kwargs): \n",
    "        \"\"\" Evaluates when new polygon is selected. Layer.toggle first!\"\"\"\n",
    "        \n",
    "        if list(kwargs.keys()) != ['event', 'properties']: # check event\n",
    "            return(None)                                   # skip basemap\n",
    "\n",
    "        i = int(kwargs[\"properties\"][\"id\"])             # get selected poly id\n",
    "        layer_row = self.layers.iloc[i]                 # get row for selected\n",
    "        layer_inst = layer_row.layer                    # get Layer class inst\n",
    "        self.selected = i\n",
    "\n",
    "        self.points.clear_layers()\n",
    "        self.points.add_layer(layer_row[\"points\"]) \n",
    "        self.mapw.center = (layer_inst.lat, layer_inst.lon)\n",
    "        self.mapw.zoom = 9\n",
    "        self.submit.disabled = True if layer_inst.dl else False\n",
    "\n",
    "        self.out1.clear_output(); self.out2.clear_output()\n",
    "        with self.out1:                             # display nan summary\n",
    "            if layer_row.layer.dl:\n",
    "                get_nan_plot(layer_row.layer.nan)\n",
    "            else:\n",
    "                display(HTML(download_msg))\n",
    "        with self.out2:\n",
    "            print(site_details.format(**layer_inst.details))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from smvjupyter import *                                    # import the UI\n",
    "\n",
    "usfs_sites = \"docs/usfs_sites/Sites_lf_geo.json\"               # USFS sites\n",
    "usfs_regions = \"docs/usfs_admin/USFS_Regional_Boundaries.json\" # admin regions\n",
    "\n",
    "app = JupyterSMV(usfs_sites)#, ancillary=usfs_regions          # init UI\n",
    "app.ui     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing -->>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Some text ...\n",
    "\n",
    "\n",
    "\n",
    "## Workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef084504e7aa4759a226d7a9f42c7f74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Map(basemap={'url': 'https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png', 'max_zoom': 19, 'attr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from smvjupyter import *                                    # import the UI\n",
    "\n",
    "usfs_sites = \"docs/usfs_sites/Sites_lf_geo.json\"               # USFS sites\n",
    "usfs_regions = \"docs/usfs_admin/USFS_Regional_Boundaries.json\" # admin regions\n",
    "\n",
    "app = JupyterSMV(usfs_sites)#, ancillary=usfs_regions          # init UI\n",
    "app.ui     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>layer</th>\n",
       "      <th>samples</th>\n",
       "      <th>points</th>\n",
       "      <th>xr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>31.774734</td>\n",
       "      <td>-109.327589</td>\n",
       "      <td>&lt;smvjupyter.Layer object at 0x000001FCDFDF4908&gt;</td>\n",
       "      <td>id        lat         lon  \\\n",
       "0    0  32.08...</td>\n",
       "      <td>LayerGroup(layers=(CircleMarker(fill_color='bl...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>31.505073</td>\n",
       "      <td>-110.536967</td>\n",
       "      <td>&lt;smvjupyter.Layer object at 0x000001FCE0F017B8&gt;</td>\n",
       "      <td>id        lat         lon  \\\n",
       "0    0  31.83...</td>\n",
       "      <td>LayerGroup(layers=(CircleMarker(color='#377eb8...</td>\n",
       "      <td>[SoilSCAPE_surface, SoilSCAPE_rootzone, AirMOS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>33.653808</td>\n",
       "      <td>-108.566810</td>\n",
       "      <td>&lt;smvjupyter.Layer object at 0x000001FCE24943C8&gt;</td>\n",
       "      <td>id        lat         lon  \\\n",
       "0    0  33.84...</td>\n",
       "      <td>LayerGroup(layers=(CircleMarker(fill_color='bl...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>35.298089</td>\n",
       "      <td>-111.641646</td>\n",
       "      <td>&lt;smvjupyter.Layer object at 0x000001FCE1453160&gt;</td>\n",
       "      <td>id        lat         lon  \\\n",
       "0    0  35.55...</td>\n",
       "      <td>LayerGroup(layers=(CircleMarker(fill_color='bl...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>33.996685</td>\n",
       "      <td>-108.673179</td>\n",
       "      <td>&lt;smvjupyter.Layer object at 0x000001FCE2515860&gt;</td>\n",
       "      <td>id        lat         lon  \\\n",
       "0    0  34.17...</td>\n",
       "      <td>LayerGroup(layers=(CircleMarker(fill_color='bl...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>34.020165</td>\n",
       "      <td>-109.401942</td>\n",
       "      <td>&lt;smvjupyter.Layer object at 0x000001FCE2515A58&gt;</td>\n",
       "      <td>id        lat         lon  \\\n",
       "0    0  34.17...</td>\n",
       "      <td>LayerGroup(layers=(CircleMarker(fill_color='bl...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>47.606681</td>\n",
       "      <td>-103.517068</td>\n",
       "      <td>&lt;smvjupyter.Layer object at 0x000001FCE2877908&gt;</td>\n",
       "      <td>id        lat         lon  \\\n",
       "0    0  48.10...</td>\n",
       "      <td>LayerGroup(layers=(CircleMarker(fill_color='bl...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>46.752166</td>\n",
       "      <td>-103.556410</td>\n",
       "      <td>&lt;smvjupyter.Layer object at 0x000001FCE27C12B0&gt;</td>\n",
       "      <td>id        lat         lon  \\\n",
       "0    0  47.27...</td>\n",
       "      <td>LayerGroup(layers=(CircleMarker(fill_color='bl...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>37.714688</td>\n",
       "      <td>-106.863892</td>\n",
       "      <td>&lt;smvjupyter.Layer object at 0x000001FCE28E0E80&gt;</td>\n",
       "      <td>id        lat         lon  \\\n",
       "0    0  37.91...</td>\n",
       "      <td>LayerGroup(layers=(CircleMarker(fill_color='bl...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>37.337869</td>\n",
       "      <td>-103.076888</td>\n",
       "      <td>&lt;smvjupyter.Layer object at 0x000001FCE2DDB908&gt;</td>\n",
       "      <td>id        lat         lon  \\\n",
       "0    0  37.82...</td>\n",
       "      <td>LayerGroup(layers=(CircleMarker(fill_color='bl...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        lat         lon                                            layer  \\\n",
       "0   0  31.774734 -109.327589  <smvjupyter.Layer object at 0x000001FCDFDF4908>   \n",
       "1   1  31.505073 -110.536967  <smvjupyter.Layer object at 0x000001FCE0F017B8>   \n",
       "2   2  33.653808 -108.566810  <smvjupyter.Layer object at 0x000001FCE24943C8>   \n",
       "3   3  35.298089 -111.641646  <smvjupyter.Layer object at 0x000001FCE1453160>   \n",
       "4   4  33.996685 -108.673179  <smvjupyter.Layer object at 0x000001FCE2515860>   \n",
       "5   5  34.020165 -109.401942  <smvjupyter.Layer object at 0x000001FCE2515A58>   \n",
       "6   6  47.606681 -103.517068  <smvjupyter.Layer object at 0x000001FCE2877908>   \n",
       "7   7  46.752166 -103.556410  <smvjupyter.Layer object at 0x000001FCE27C12B0>   \n",
       "8   8  37.714688 -106.863892  <smvjupyter.Layer object at 0x000001FCE28E0E80>   \n",
       "9   9  37.337869 -103.076888  <smvjupyter.Layer object at 0x000001FCE2DDB908>   \n",
       "\n",
       "                                             samples  \\\n",
       "0      id        lat         lon  \\\n",
       "0    0  32.08...   \n",
       "1      id        lat         lon  \\\n",
       "0    0  31.83...   \n",
       "2      id        lat         lon  \\\n",
       "0    0  33.84...   \n",
       "3      id        lat         lon  \\\n",
       "0    0  35.55...   \n",
       "4      id        lat         lon  \\\n",
       "0    0  34.17...   \n",
       "5      id        lat         lon  \\\n",
       "0    0  34.17...   \n",
       "6      id        lat         lon  \\\n",
       "0    0  48.10...   \n",
       "7      id        lat         lon  \\\n",
       "0    0  47.27...   \n",
       "8      id        lat         lon  \\\n",
       "0    0  37.91...   \n",
       "9      id        lat         lon  \\\n",
       "0    0  37.82...   \n",
       "\n",
       "                                              points  \\\n",
       "0  LayerGroup(layers=(CircleMarker(fill_color='bl...   \n",
       "1  LayerGroup(layers=(CircleMarker(color='#377eb8...   \n",
       "2  LayerGroup(layers=(CircleMarker(fill_color='bl...   \n",
       "3  LayerGroup(layers=(CircleMarker(fill_color='bl...   \n",
       "4  LayerGroup(layers=(CircleMarker(fill_color='bl...   \n",
       "5  LayerGroup(layers=(CircleMarker(fill_color='bl...   \n",
       "6  LayerGroup(layers=(CircleMarker(fill_color='bl...   \n",
       "7  LayerGroup(layers=(CircleMarker(fill_color='bl...   \n",
       "8  LayerGroup(layers=(CircleMarker(fill_color='bl...   \n",
       "9  LayerGroup(layers=(CircleMarker(fill_color='bl...   \n",
       "\n",
       "                                                  xr  \n",
       "0                                               None  \n",
       "1  [SoilSCAPE_surface, SoilSCAPE_rootzone, AirMOS...  \n",
       "2                                               None  \n",
       "3                                               None  \n",
       "4                                               None  \n",
       "5                                               None  \n",
       "6                                               None  \n",
       "7                                               None  \n",
       "8                                               None  \n",
       "9                                               None  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#xr_complete = xr.open_dataset(\"usfs_sites_smv.nc\")  # open netCDF\n",
    "#xr_complete\n",
    "app.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'in situ': {'nodata': ['SoilSCAPE_surface',\n",
       "   'SoilSCAPE_rootzone',\n",
       "   'AirMOSS_in-ground_surface',\n",
       "   'AirMOSS_in-ground_rootzone',\n",
       "   'COSMOS_surface',\n",
       "   'COSMOS_rootzone',\n",
       "   'SCAN_surface',\n",
       "   'SCAN_rootzone',\n",
       "   'SNOTEL_surface',\n",
       "   'SNOTEL_rootzone'],\n",
       "  'yesdata': ['CRN_surface', 'CRN_rootzone'],\n",
       "  'summary':      CRN_surface  CRN_rootzone\n",
       "  0              0             0\n",
       "  1              0             0\n",
       "  2              0             0\n",
       "  3              0             0\n",
       "  4           2197          2197\n",
       "  5              0             0\n",
       "  6              0             0\n",
       "  7              0             0\n",
       "  8              0             0\n",
       "  9              0             0\n",
       "  10             0             0\n",
       "  11             0             0\n",
       "  12             0             0\n",
       "  13             0             0\n",
       "  14             0             0\n",
       "  15             0             0\n",
       "  16             0             0\n",
       "  17             0             0\n",
       "  nan       109025        109025},\n",
       " 'airborne': {'nodata': [],\n",
       "  'yesdata': ['AirMOSS_L2_3_surface',\n",
       "   'AirMOSS_L2_3_rootzone',\n",
       "   'AirMOSS_L4_rootzone'],\n",
       "  'summary':      AirMOSS_L2_3_surface  AirMOSS_L2_3_rootzone  AirMOSS_L4_rootzone\n",
       "  0                      16                     19                 1076\n",
       "  1                      16                     19                 1076\n",
       "  2                       0                      0                    0\n",
       "  3                       0                      0                    0\n",
       "  4                       0                      0                    0\n",
       "  5                       0                      0                    0\n",
       "  6                       0                      0                    0\n",
       "  7                       0                      0                    0\n",
       "  8                       0                      0                    0\n",
       "  9                       0                      0                    0\n",
       "  10                      0                      0                    0\n",
       "  11                      0                      0                    0\n",
       "  12                      0                      0                    0\n",
       "  13                      0                      0                    0\n",
       "  14                      0                      0                    0\n",
       "  15                      0                      0                    0\n",
       "  16                      0                      0                    0\n",
       "  17                      0                      0                    0\n",
       "  nan                111190                 111184               109070},\n",
       " 'spaceborne': {'nodata': [],\n",
       "  'yesdata': ['SMAP_surface',\n",
       "   'SMAP_rootzone',\n",
       "   'NEE_mean',\n",
       "   'GPP_mean',\n",
       "   'GRACE_surface_pctl',\n",
       "   'GRACE_rootzone_pctl'],\n",
       "  'summary':      SMAP_surface  SMAP_rootzone  NEE_mean  GPP_mean  GRACE_surface_pctl  \\\n",
       "  0            1431           1431      1428      1428                 258   \n",
       "  1            1431           1431      1428      1428                 258   \n",
       "  2            1427           1427      1417      1417                 805   \n",
       "  3            1427           1427      1417      1417                 805   \n",
       "  4            1431           1431      1428      1428                 795   \n",
       "  5            1427           1427      1417      1417                 805   \n",
       "  6            1427           1427      1417      1417                 805   \n",
       "  7            1427           1427      1417      1417                 805   \n",
       "  8            1427           1427      1417      1417                 805   \n",
       "  9            1427           1427      1417      1417                 805   \n",
       "  10           1427           1427      1417      1417                 805   \n",
       "  11           1427           1427      1417      1417                 805   \n",
       "  12           1427           1427      1417      1417                 805   \n",
       "  13           1427           1427      1417      1417                 805   \n",
       "  14           1427           1427      1417      1417                 805   \n",
       "  15           1427           1427      1417      1417                 805   \n",
       "  16           1427           1427      1417      1417                 805   \n",
       "  17           1427           1427      1417      1417                 805   \n",
       "  nan         85524          85524     85683     85683               97836   \n",
       "  \n",
       "       GRACE_rootzone_pctl  \n",
       "  0                    258  \n",
       "  1                    258  \n",
       "  2                    805  \n",
       "  3                    805  \n",
       "  4                    795  \n",
       "  5                    805  \n",
       "  6                    805  \n",
       "  7                    805  \n",
       "  8                    805  \n",
       "  9                    805  \n",
       "  10                   805  \n",
       "  11                   805  \n",
       "  12                   805  \n",
       "  13                   805  \n",
       "  14                   805  \n",
       "  15                   805  \n",
       "  16                   805  \n",
       "  17                   805  \n",
       "  nan                97836  }}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.layers.iloc[1].layer.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import RadioButtons, Checkbox, ToggleButtons\n",
    "\n",
    "#dir(ToggleButtons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_xrarrays(xrds):\n",
    "    \"\"\" \"\"\"\n",
    "    \n",
    "    stack = np.stack([xrds[v].data for v in xrds])    # collapse dataset into a stacked array\n",
    "    data = dict(\n",
    "        mean = np.nanmean(stack, axis=0),             # calculate mean over time axis (0)\n",
    "        std = np.nanstd(stack, axis=0),               # calculate mean over time axis (0)\n",
    "        time = xrds.time.data)\n",
    "    \n",
    "    return(pd.DataFrame(\n",
    "        data, \n",
    "        columns=[\"Time\", \"Mean\", \"Std\"], \n",
    "        index=data[\"time\"]))\n",
    "\n",
    "\n",
    "class Plotter:\n",
    "    \"\"\"Generates the map/plot side-by-side widget container.\"\"\"\n",
    "    \n",
    "    figure_args = dict(sharex=True, figsize=(15, 8))\n",
    "    legend_args = dict(loc=0, framealpha=1)\n",
    "    error_msg = \"\"\"\n",
    "        <p style=\"text-align:center;\">\n",
    "        <b>Error:</b> unable to plot this combination for some reason.\n",
    "        </p>\n",
    "        \"\"\"\n",
    "    \n",
    "    def __init__(self, layer, nrow=2, ncol=1, mw=\"25%\", ow=\"75%\", zoom=8):\n",
    "\n",
    "        self.layerr = layer\n",
    "        self.nrow, self.ncol = nrow, ncol\n",
    "        \n",
    "        self.layero = layer.layer\n",
    "        self.xr = layer.xr                                      # xarray.Dataset\n",
    "        self.nan = self.layero.nan                              # nan summary\n",
    "        \n",
    "        variables = [i for L in  [n[\"yesdata\"] for n in self.nan.values()] for i in L]\n",
    "        self.xrs = self.xr[variables]\n",
    "\n",
    "        # --------------------------------------------------------------------\n",
    "        # selection ui\n",
    "        \n",
    "        Type = list(set([self.xrs[d].attrs[\"type\"] for d in self.xrs]))\n",
    "        self.ChkbxType = [Checkbox(description=a, value=True) for a in Type]\n",
    "        self.ChkbxZone = [Checkbox(description=a, value=True) for a in ['surface', 'rootzone']]\n",
    "        \n",
    "        self.TypeUI = VBox([HTML(\"<b>Platform type: </b>\"), interactive(\n",
    "            self.type_handler,\n",
    "            **{c.description: c.value for c in self.ChkbxType})])\n",
    "        \n",
    "        self.ZoneUI = VBox([HTML(\"<b>Soil zone:</b>\"), interactive(\n",
    "            self.zone_handler,\n",
    "            **{c.description: c.value for c in self.ChkbxZone})])\n",
    "  \n",
    "        self.bybutton = ToggleButtons(\n",
    "            options=[\"day\", \"week\", \"month\", \"year\"],\n",
    "            value=\"day\",\n",
    "            description='Interval: ',\n",
    "            button_style=\"info\")\n",
    "        self.bybutton.observe(self.bttn_handler)\n",
    "        \n",
    "        self.selectionui = VBox([self.bybutton, HBox([\n",
    "            self.TypeUI, \n",
    "            self.ZoneUI])])\n",
    "        \n",
    "        # --------------------------------------------------------------------\n",
    "        # map/plot ui\n",
    "        \n",
    "        self.mapw = Map(                                             # map widget\n",
    "            layers=(self.layero.layer, layer.points, bmap,), \n",
    "            center=(layer.lat, layer.lon), \n",
    "            zoom=zoom, width=mw)\n",
    "        self.output = Output(layout={\"width\": ow})                   # Output widget \n",
    "        self.mapplotui = HBox([self.mapw, self.output])              # Map/plot ui\n",
    "        \n",
    "        # --------------------------------------------------------------------\n",
    "        # master ui and init\n",
    "        \n",
    "        self.selected = {\"type\":Type, \"soil_zone\":['surface', 'rootzone']}\n",
    "        self.ui = VBox([self.mapplotui, self.selectionui])\n",
    "        self.draw()\n",
    "\n",
    "    # ------------------------------------------------------------------------\n",
    "\n",
    "    def type_handler(self, **kwargs):\n",
    "        \"\"\" \"\"\"\n",
    "        self.selected[\"type\"] = [k for k,v in kwargs.items() if v]\n",
    "    \n",
    "    def zone_handler(self, **kwargs):\n",
    "        \"\"\" \"\"\"\n",
    "        self.selected[\"soil_zone\"] = [k for k,v in kwargs.items() if v]\n",
    "    \n",
    "    def bttn_handler(self, b):\n",
    "        \"\"\" \"\"\"\n",
    "        self.selected[\"By\"] = self.bybutton.value\n",
    "\n",
    "    \n",
    "    def draw(self):\n",
    "        \"\"\" \"\"\"\n",
    "        self.output.clear_output()                               \n",
    "        data = self.xrs\n",
    "        \n",
    "        By = self.bybutton.value\n",
    "        if By is not \"day\":                                     # maybe aggregate\n",
    "            data = data.groupby(\"time.\"+str(By)).mean() \n",
    "        \n",
    "        with self.output:\n",
    "            fig, axs = plt.subplots(nrows=self.nrow, ncols=self.ncol, **self.figure_args)\n",
    "\n",
    "            # ax1: soil moisture\n",
    "            for T in self.selected[\"type\"]:\n",
    "                D1 = data.filter_by_attrs(type=T)\n",
    "                for Z in self.selected[\"soil_zone\"]:\n",
    "                    D2 = D1.filter_by_attrs(soil_zone=Z).sel(stat=\"Mean\").mean(dim=\"sample\")\n",
    "                    self.tmpdf = calc_xrarrays(D2)\n",
    "                    self.tmpdf.plot(x=\"Time\", y=\"Mean\", ax=axs[0])            \n",
    "            axs[0].set_title(\"Mean soil moisture by platform type\")                  # axis title\n",
    "            axs[0].set_ylabel(\"m3/m3\")\n",
    "            \n",
    "            # ax2: productivity\n",
    "            data2 = data.filter_by_attrs(units=\"g m-2 d-1\")\n",
    "            for name, ds in data2.items():\n",
    "                axs[1].set_title(ds.attrs[\"description\"])                        # axis title\n",
    "                tdata = ds.sel(stat=\"Mean\")\n",
    "                tmean, tstd = tdata.mean(\"sample\"), tdata.std(\"sample\")# get mean,std of sample dimension\n",
    "                tmean.plot.line(label=name, ax=axs[1], add_legend=False, marker=None)         # plot a line\n",
    "            axs[1].set_ylabel(\"g m-2 d-1\")                                       # axis labels\n",
    "            \n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b9d2dda96b948b88e9dea6b1079cd16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Map(basemap={'url': 'https://{s}.tile.openstreetmap.org/{z}/{x}/{y}.png', 'max_z…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "selected_layer = app.layers.iloc[app.selected]\n",
    "p = Plotter(selected_layer)\n",
    "p.ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time   NaN\n",
       "Mean   NaN\n",
       "Std    NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.tmpdf.max(skipna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fds = p.xr.filter_by_attrs(type='airborne').sel(stat=\"Mean\")\n",
    "xr.concat([fds[d] for d in fds]).expand_dims()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_layer = app.layers.iloc[app.selected]\n",
    "xrdataset = selected_layer.xr\n",
    "\n",
    "mapw1, output1 = poly_mapper(selected_layer)                                 # get some widgets\n",
    "display(HBox([mapw1, output1]))\n",
    "\n",
    "plotters = [(xrdataset[\"SMAP_surface\"], 0, None, None),                      # a list of lines to plot and\n",
    "            (xrdataset[\"SMAP_rootzone\"], 0, None, \"m3/m3\"),                  #   their respective properties:\n",
    "            (xrdataset[\"GPP_mean\"], 1, \"green\", None),                       #   dataset, axis, color\n",
    "            (xrdataset[\"NEE_mean\"], 1, \"purple\", \"g m-2 d-1\")]\n",
    "\n",
    "\n",
    "\n",
    "with output1:\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=1, sharex=True, figsize=(15, 8))  # initialize the figure\n",
    "    for p in plotters:                                                       # loop over list above\n",
    "        data, axis_num, line_color, y_label = p                              # dataset, axis, color\n",
    "        line_args = {\"x\": \"time\", \"add_legend\": False,                       # a dictionary of line properties\n",
    "                    \"ax\": axs[axis_num], \n",
    "                    \"color\": line_color}                                     \n",
    "        data = data.sel(stat=\"Mean\")\n",
    "        tmpmean, tmpstd = data.mean(\"sample\"), data.std(\"sample\")            # get mean,std of sample dimension\n",
    "        tmpmean.plot.line(label=data.attrs[\"description\"], **line_args)      # plot a line\n",
    "        axs[axis_num].set_title(None)                                        # axis title\n",
    "        axs[axis_num].set_ylabel(y_label)                                    # plot axis labels\n",
    "    \n",
    "    axs[0].legend(loc=0, framealpha=1); axs[1].legend(loc=0, framealpha=1)   # set legend properties\n",
    "    axs[0].set_title(\"SMAP Datasets: USFS site 1\", loc='left')               # plot title\n",
    "    axs[0].set_xlabel(None)                                                  # remove axis 1 xlabel\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_nan_plot(layer_row.layer.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyr = app.layers.iloc[1]\n",
    "lyrlyr = lyr.layer\n",
    "testnan = lyrlyr.nan\n",
    "\n",
    "a = testnan[\"in situ\"]\n",
    "b = testnan[\"airborne\"]\n",
    "c = testnan[\"spaceborne\"]\n",
    "\n",
    "a[\"summary\"].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = lyr.xr\n",
    "dsnull = ds.sel(stat=\"Mean\").isnull()\n",
    "NEE_mean = dsnull[\"NEE_mean\"]\n",
    "np.count_nonzero(NEE_mean.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsnull.apply(lambda x: x is True, dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as dt\n",
    "\n",
    "\n",
    "def get_nan_summary(xrds): \n",
    "    \"\"\" \"\"\"\n",
    "    nandict = {\"in situ\": dict(), \"airborne\": dict(), \"spaceborne\": dict()}\n",
    "\n",
    "    for pt in nandict.keys():\n",
    "\n",
    "        # get the datasets for the current platform\n",
    "        ds = xrds.filter_by_attrs(type=pt).sel(stat=\"Mean\", drop=True)\n",
    "\n",
    "        # get fraction of null dataset by timestep for all samples\n",
    "        dsnull = ds.isnull()\n",
    "\n",
    "        # get variables with nodata; variables with data; valid counts\n",
    "        nodata, yesdata, data = [], [], {}\n",
    "        for name, dataset in dsnull.items():\n",
    "            if dataset.data.all(): #dataset.isnull().mean()==1\n",
    "                nodata.append(name)\n",
    "            else:\n",
    "                yesdata.append(name)\n",
    "                dataset.data = np.logical_not(dataset.data)\n",
    "                data[name] = dataset.mean(\"sample\").data\n",
    "        \n",
    "        nandict[pt].update({\n",
    "            \"nodata\": nodata, \n",
    "            \"yesdata\": yesdata, \n",
    "            \"summary\": pd.DataFrame(data, index=ds.time.data)})\n",
    "        \n",
    "    return(nandict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nands = get_nan_summary(ds)\n",
    "spaceborne = nands['spaceborne'][\"summary\"]\n",
    "spaceborne.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaceborne.()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(\n",
    "    nstack, \n",
    "    aspect='auto', \n",
    "    cmap=\"tab20c\", \n",
    "    interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnancount = np.count_nonzero(data)\n",
    "                yesdata[name].append(potential_obs_count-obstotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        # update summary dictionary\n",
    "        ix = list(range(samplelen))+[\"nan\"]   \n",
    "        nandict[pt].update({                      \n",
    "            \"nodata\": nodata, \n",
    "            \"yesdata\": yesdata, \n",
    "            \"summary\": pd.DataFrame(obscount, index=ix)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        if len(data)>0:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as dt\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "df.amin = pd.to_datetime(df.amin).astype(datetime)\n",
    "df.amax = pd.to_datetime(df.amax).astype(datetime)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax = ax.xaxis_date()\n",
    "ax = plt.hlines(df.index, dt.date2num(df.amin), dt.date2num(df.amax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_mapper(lyr, mw=\"25%\", ow=\"75%\", zoom=8):\n",
    "    \"\"\"Generates the map/plot side-by-side widget container.\"\"\"\n",
    "\n",
    "    l = (lyr[\"layer\"].layer, lyr.points, bmap,)\n",
    "    m = Map(layers=l, center=(lyr[\"lat\"], lyr[\"lon\"]), zoom=zoom, width=mw)\n",
    "    o = Output(layout={\"width\": ow})\n",
    "    \n",
    "    return((m,o))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = [\n",
    "    'g m-2 d-1', \n",
    "    'm3/m3', \n",
    "    'degrees C', \n",
    "    'mm/day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyr = app.layers.iloc[5]\n",
    "lyrxr = lyr.xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plottable(xds):\n",
    "    \"\"\" \"\"\"\n",
    "    plotvars = []\n",
    "    for v in list(xds.variables):\n",
    "        if v not in ignorevars:\n",
    "            if not allnan(xds[v]):\n",
    "                plotvars.append(v)\n",
    "    return(plotvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapw2, output2 = poly_mapper(lyr)\n",
    "display(HBox([output2, mapw2]))\n",
    "\n",
    "insitu = lyrxr.filter_by_attrs(type=\"in situ\")            # select in situ, and\n",
    "airborne = lyrxr.filter_by_attrs(type=\"airborne\")         # airborne datasets\n",
    "\n",
    "widgets = dict(\n",
    "    Source=,\n",
    "    Type=[\"in situ\", \"airborne\"],\n",
    "    Depth=['surface', 'rootzone'],\n",
    "    By=[\"None\", \"year\", \"month\", \"week\", \"day\"])\n",
    "\n",
    "\n",
    "def update(Source, Type, Depth):\n",
    "    \n",
    "    \n",
    "\n",
    "with output2:\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=1, sharex=True, figsize=(15, 8))\n",
    "    plotters = [(insitu, axs[0], \"In situ soil moisture\"), \n",
    "                (airborne, axs[1], \"Airborne soil moisture\")]\n",
    "    for p in plotters:\n",
    "        data, ax, title = p\n",
    "        data = data.sel(stat=\"Mean\").mean(dim=\"sample\")         # select stat \"Mean\" and site N. avg sample dim\n",
    "        tmpstack = np.stack([data[v].data for v in data])       # collapse dataset into a stacked array\n",
    "        tmpmean = np.nanmean(tmpstack, axis=0)                  # calculate mean over time axis (0)\n",
    "        tmpstd = np.nanstd(tmpstack, axis=0)                    # calculate mean over time axis (0)\n",
    "        tmptime = data.time.data\n",
    "        \n",
    "        ax.grid('on', alpha=0.25)\n",
    "        ax.plot_date(x=tmptime, y=tmpmean, color=\"black\", linestyle=\"solid\", marker=None)\n",
    "        ax.fill_between(tmptime, (tmpmean-tmpstd), (tmpmean+tmpstd), color=\"gray\", alpha=0.2)\n",
    "        ax.set_title(title+\" [avg of available SMV datasets]\")\n",
    "        ax.set_ylabel(\"m3/m3\")\n",
    "        if not np.count_nonzero(~np.isnan(tmpmean))==0:\n",
    "            ax.set_ylim(np.nanmin(tmpmean), np.nanmax(tmpmean))\n",
    "        \n",
    "    \n",
    "    widgets = dict(Dataset=plotvars, Statistic=[\"Mean\",\"Min\",\"Max\"])\n",
    "    p = interactive(update, **widgets)\n",
    "    display(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyr = app.layers.iloc[0]\n",
    "xds = lyr.xr\n",
    "xdsm = xds.sel(stat=\"Mean\", drop=True)\n",
    "xdsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdsm[\"SMAP_surface\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = lyr.samples.iloc[0].samp\n",
    "sampdf = samp.df.AirMOSS_L4_rootzone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform_types = {\"in situ\": {}, \"airborne\": {}, \"spaceborne\": {}}\n",
    "\n",
    "for pt in platform_types.keys():\n",
    "    \n",
    "    # get the datasets for the current platform\n",
    "    pds = xds.filter_by_attrs(type=pt).sel(stat=\"Mean\", drop=True)\n",
    "    timelen, samplelen = pds.time.size, pds.sample.size\n",
    "    potential_obs_count = timelen*samplelen\n",
    "    \n",
    "    # get variables with nodata; variables with data; valid counts\n",
    "    nodata, yesdata, obscount = [], [], {}\n",
    "    for name, dataset in pds.items():\n",
    "        if allnan(dataset):\n",
    "            nodata.append(name)\n",
    "        else:\n",
    "            yesdata.append(name)\n",
    "            obscount[name], obstotal = [], 0\n",
    "            for i in range(samplelen):\n",
    "                samp = dataset.sel(sample=i)\n",
    "                count = numvalid(samp)\n",
    "                obscount[name].append(count)\n",
    "                obstotal += count\n",
    "            obscount[name].append(potential_obs_count-obstotal)\n",
    "\n",
    "    # update summary dictionary\n",
    "    ix = list(range(samplelen))+[\"nan\"]\n",
    "    platform_types[pt].update({\n",
    "        \"nodata\": nodata, \n",
    "        \"yesdata\": yesdata, \n",
    "        \"summary\": pd.DataFrame(obscount, index=ix)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spaceborne = platform_types[\"spaceborne\"]\n",
    "spacebornedf = spaceborne[\"summary\"]\n",
    "spacebornedf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nan_summary(nandict): \n",
    "    \n",
    "    n, stypes, sratio = 0, [], {'height_ratios': []}\n",
    "    for stype, nandata in nandict.items():\n",
    "        cnt = len(nandata[\"yesdata\"])\n",
    "        if cnt!=0:\n",
    "            n += 1\n",
    "            stypes.append((stype, nandata[\"summary\"]))\n",
    "            sratio['height_ratios'].append(cnt)\n",
    "\n",
    "    fig, axs = plt.subplots(n, 1, sharex=True, figsize=(7,4), gridspec_kw=sratio)\n",
    "    for i, d in enumerate(stypes):\n",
    "        d[1].T.plot.barh(stacked=True, ax=axs[i], colormap=\"tab20c\", legend=False)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    leg = dict(title=\"samples\", loc=\"top right\", bbox_to_anchor=(1, 1), framealpha=1) \n",
    "    axs[0].legend(ncol=ceil(len(stypes[0][1].index)/10), **leg)\n",
    "    axs[0].set_title(\"n observations by dataset\")\n",
    "    \n",
    "    return(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "testfig = get_nan_summary(platform_types)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_legend_ncols = lambda df: ceil(len(df.index)/10)\n",
    "legends_args = dict(\n",
    "    title=\"samples\", \n",
    "    loc=0, #\"top left\", \n",
    "    #bbox_to_anchor=(0.75, 1), \n",
    "    framealpha=1) \n",
    "\n",
    "def get_nan_summary(xrdataset): \n",
    "    \"\"\" \"\"\"\n",
    "    nandict = {\"in situ\": {}, \"airborne\": {}, \"spaceborne\": {}}\n",
    "\n",
    "    for pt in nandict.keys():\n",
    "\n",
    "        # get the datasets for the current platform\n",
    "        pds = xrdataset.filter_by_attrs(type=pt).sel(stat=\"Mean\", drop=True)\n",
    "        timelen, samplelen = pds.time.size, pds.sample.size\n",
    "        potential_obs_count = timelen*samplelen\n",
    "\n",
    "        # get variables with nodata; variables with data; valid counts\n",
    "        nodata, yesdata, obscount = [], [], {}\n",
    "        for name, dataset in pds.items():\n",
    "            if allnan(dataset):\n",
    "                nodata.append(name)\n",
    "            else:\n",
    "                yesdata.append(name)\n",
    "                obscount[name], obstotal = [], 0\n",
    "                for i in range(samplelen):\n",
    "                    samp = dataset.sel(sample=i)\n",
    "                    count = numvalid(samp)\n",
    "                    obscount[name].append(count)\n",
    "                    obstotal += count\n",
    "                obscount[name].append(potential_obs_count-obstotal)\n",
    "        \n",
    "        # update summary dictionary\n",
    "        ix = list(range(samplelen))+[\"nan\"]   \n",
    "        nandict[pt].update({                      \n",
    "            \"nodata\": nodata, \n",
    "            \"yesdata\": yesdata, \n",
    "            \"summary\": pd.DataFrame(obscount, index=ix)})\n",
    "\n",
    "    n, stypes, sratio = 0, [], {'height_ratios': []}\n",
    "    for stype, nandata in nandict.items():\n",
    "        cnt = len(nandata[\"yesdata\"])\n",
    "        if cnt!=0:\n",
    "            n += 1\n",
    "            stypes.append((stype, nandata[\"summary\"]))\n",
    "            sratio['height_ratios'].append(cnt)\n",
    "\n",
    "    if n>1:\n",
    "        fig, axs = plt.subplots(nrows=n, gridspec_kw=sratio, **figure_args)\n",
    "        for i, d in enumerate(stypes):\n",
    "            d[1].T.plot.barh(ax=axs[i],**bar_args)\n",
    "    else:\n",
    "        fig, ax = plt.plot(figsize=(7,4))\n",
    "        stypes[0][1].T.plot.barh(ax=ax,**bar_args)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    axs[0].legend(ncol=get_legend_ncols(stypes[0][1]), **legends_args)\n",
    "    axs[0].set_title(\"n observations by dataset\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_nan_summary(xds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "font = {\"family\": \"normal\", \"weight\": \"normal\", \"size\": 14}       # some matplotlib settings ->\n",
    "plt.rc(\"font\", **font)      \n",
    "plt.rcParams['figure.figsize'] = [14, 5]                          #"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
